import streamlit as st
from ultralytics import YOLO
from PIL import Image
import cv2
import tempfile
import os

# ==============================
# Configuration UI
# ==============================
st.set_page_config(
    page_title="DÃ©tection Poubelle Pleine/Vide",
    page_icon="ğŸ—‘ï¸",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ==============================
# CSS
# ==============================
st.markdown("""
    <style>
        .title {
            text-align: center;
            font-size: 36px !important;
            color: #4CAF50;
            font-weight: bold;
        }
        .subtitle {
            color: #555;
            font-size: 20px;
            margin-bottom: 15px;
        }
        .box {
            padding: 15px;
            background-color: #f9f9f9;
            border-radius: 10px;
            border: 1px solid #ddd;
            margin-top: 10px;
        }
    </style>
""", unsafe_allow_html=True)

# ==============================
# Charger modÃ¨le YOLO
# ==============================
model_path = "best.pt"
model = YOLO(model_path)

# ==============================
# UI principale
# ==============================
st.markdown("<h1 class='title'>ğŸ—‘ï¸ DÃ©tection Poubelle Pleine / Vide</h1>", unsafe_allow_html=True)
st.markdown("<p class='subtitle'>Analyse dâ€™images et de vidÃ©os avec YOLOv8</p>", unsafe_allow_html=True)

mode = st.radio("ğŸ›ï¸ Choisir le mode :", ["Image", "VidÃ©o"])

# ==============================
# MODE IMAGE
# ==============================
if mode == "Image":
    uploaded_file = st.file_uploader("ğŸ“¥ Importer une image", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        st.markdown("<div class='box'>ğŸ“· Image originale</div>", unsafe_allow_html=True)
        img = Image.open(uploaded_file)
        st.image(img, use_column_width=True)

        with st.spinner("ğŸ” Analyse en cours..."):
            results = model.predict(img)

        detected_labels = []

        for box in results[0].boxes:
            cls = int(box.cls[0])
            label = results[0].names[cls]
            detected_labels.append(label)

        st.subheader("ğŸ“ RÃ©sultats")

        if len(detected_labels) == 0:
            st.error("âŒ Aucune poubelle dÃ©tectÃ©e")
        else:
            for label in detected_labels:
                if "vide" in label.lower():
                    st.success("ğŸŸ¢ Poubelle vide dÃ©tectÃ©e")
                elif "pleine" in label.lower():
                    st.warning("ğŸŸ¡ Poubelle pleine dÃ©tectÃ©e")
                else:
                    st.info(f"Objet dÃ©tectÃ© : {label}")

        st.markdown("<div class='box'>ğŸ–¼ï¸ Image annotÃ©e</div>", unsafe_allow_html=True)
        st.image(results[0].plot(), use_column_width=True)

# ==============================
# MODE VIDEO
# ==============================
elif mode == "VidÃ©o":

    uploaded_video = st.file_uploader("ğŸ“¥ Importer une vidÃ©o", type=["mp4", "avi", "mov"])
    
    if uploaded_video:

        # ğŸ”¹ Sauvegarde de la vidÃ©o uploadÃ©e dans un fichier temporaire
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_video.read())

        st.markdown("<div class='box'>ğŸ¬ VidÃ©o originale</div>", unsafe_allow_html=True)
        st.video(tfile.name)

        if st.button("ğŸ” Lancer la dÃ©tection"):

            with st.spinner("â³ Analyse vidÃ©o en cours..."):

                cap = cv2.VideoCapture(tfile.name)

                # ğŸ”¹ IMPORTANT : Format compatible Streamlit Cloud
                output_path = "output_detected.webm"
                fourcc = cv2.VideoWriter_fourcc(*"VP90")  # codec VP9 pour WebM

                fps = cap.get(cv2.CAP_PROP_FPS)
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

                out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break

                    results = model(frame)
                    annotated_frame = results[0].plot()

                    out.write(annotated_frame)

                cap.release()
                out.release()

            st.success("ğŸ‰ DÃ©tection terminÃ©e !")

            st.markdown("<div class='box'>ğŸŸ© VidÃ©o annotÃ©e</div>", unsafe_allow_html=True)

            # ğŸ”¹ Affichage immÃ©diat de la vidÃ©o dÃ©tectÃ©e
            with open(output_path, "rb") as f:
                st.video(f.read())

            # ğŸ”¹ TÃ©lÃ©chargement optionnel
            with open(output_path, "rb") as f:
                st.download_button(
                    "ğŸ“¥ TÃ©lÃ©charger la vidÃ©o annotÃ©e",
                    f,
                    file_name="video_detected.webm",
                    mime="video/webm"
                )
